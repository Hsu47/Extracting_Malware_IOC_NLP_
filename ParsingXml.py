import requests
import re

from bs4 import BeautifulSoup
from datetime import datetime
import os
path = os.getcwd()
path += '\chromedriver.exe'
headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}


## Domain

def DeleteInvalidDomain(domainList):
    ##刪除invalid的domain，dll 或者 exe 結尾。
    temp = domainList.copy()
    for j in temp:
        if j.endswith('.dll')|j.endswith('.exe'):
            domainList.remove(j)
    return domainList

def GetXmlDomain(index,df,domainList):

    #print('[INFO]Parsing Xml Domain start!')

    if df.loc[index, 'Stix'].startswith('https'):
        url = df.loc[index, 'Stix']
        r = requests.get(url)
        soup = BeautifulSoup(r.text, "html.parser")
        for tag in soup.find_all('uriobj:value'):
            # if '@' in tag.text:
            #     continue
            domainList.append(tag.text)
        for tag2 in soup.find_all('domainnameobj:value'):
            domainList.append(tag2.text)
    domainList = list(set(domainList))
    return domainList



def GetXmlIP(index,df,ipList):
    ## IP
    #print('[INFO]Parsing Xml IP start!')
    if df.loc[index, 'Stix'].startswith('https'):
        url = df.loc[index, 'Stix']
        r = requests.get(url)
        soup = BeautifulSoup(r.text, "html.parser")
        for tag in soup.find_all('addressobj:address_value'):
            ipList.append(tag.text)
    ipList = list(set(ipList))
    return ipList

def GetXmlHash(index,df,hashList):

    ## Hash
    #print('[INFO]Parsing Xml Hash start!')
    if df.loc[index, 'Stix'].startswith('https'):
        url = df.loc[index, 'Stix']
        r = requests.get(url)
        soup = BeautifulSoup(r.text, "html.parser")
        for tag in soup.find_all('cyboxcommon:simple_hash_value'):
            hashList.append(tag.text)
    hashList = list(set(hashList))
    return hashList

# def GetXmlCVE(df,cveList):
#
# ## CVE
# for i in range(len(df)):
#     if df.loc[i, 'Stix'].startswith('https'):
#         url = df.loc[i, 'Stix']
#         r = requests.get(url)
#         soup = BeautifulSoup(r.text, "html.parser")
#         for tag in soup.find_all('cyboxcommon:simple_hash_value'):
#             hashList.append(tag.text)
# hashList = list(set(hashList))
# return df, hashList
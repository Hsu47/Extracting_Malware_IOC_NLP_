import requests
import re
from ParsingXml import GetXmlIP,GetXmlDomain,GetXmlHash
from bs4 import BeautifulSoup
from datetime import datetime
import os
path = os.getcwd()
path += '\chromedriver.exe'
headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}


## Domain

def DeleteInvalidDomain(domainList):
    ##刪除invalid的domain，dll 或者 exe 結尾。
    temp = domainList.copy()
    for j in temp:
        if j.endswith('.dll')|j.endswith('.exe'):
            domainList.remove(j)
    return domainList

def GetDomain(df,flag):

    print('[INFO]Parsing Domain start!')

    for i in range(len(df)):
        domainList = []
        url = df['Url'][i]
        r = requests.get(url,headers = headers)
        soup = BeautifulSoup(r.text,"html.parser")
        if (flag == 0):##Uscert
            sel = soup.select("article")
        elif(flag == 1):##Malwarebytes
            sel = soup.select("#articleBody")
        for s in sel:
            temp = s.get_text(strip=True, separator=" ") ## 得到文章內容
            temp = re.sub(r'[\[\]]','',temp) ##去除保護方框 e.g. abc[.]com -> abc.com
            #temp = re.sub(r'.dll|.exe','invalid',temp)
            domainList = re.findall(r'(?:(?!-)[A-Za-z0-9-//]{1,63}(?<!-)\.){1,}[A-za-z0-9]{2,63}\b',temp) ##拿domain
            domainList = list(set(domainList)) ##去除重複
            #domainList = DeleteInvalidDomain(domainList) ##刪除dll跟exe
        domainList = GetXmlDomain(i, df, domainList)
        df.loc[i,'Domain'] = str(domainList)

    return df


def GetIP(df,flag):
    ## IP
    print('[INFO]Parsing IP start!')

    for i in range(len(df)):
        ipList = []
        url = df['Url'][i]
        r = requests.get(url,headers = headers)
        soup = BeautifulSoup(r.text,"html.parser")
        if (flag == 0):  ##Uscert
            sel = soup.select("article")
        elif (flag == 1):  ##Malwarebytes
            sel = soup.select("#articleBody")
        for s in sel:
            temp = s.get_text(strip=True, separator=" ")
            temp = re.sub(r'[\[\]]','',temp) #去除保護符號 e.g. 128[.]123[.]4[.]111 -> 128.123.4.111
            temp = re.sub(r'(dot)','.',temp) #去除保護符號 e.g. 128(.)123(.)4(.)111 -> 128.123.4.111
            ipList = re.findall(r'(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)',temp)
            ipList = list(set(ipList)) ##去除重複
        ipList = GetXmlIP(i, df, ipList)
        df.loc[i,'IP'] = str(ipList)
    return df

def GetHash(df,flag):
    ## Hash
    print('[INFO]Parsing Hash start!')
    for i in range(len(df)):
        hashList = []
        url = df['Url'][i]
        r = requests.get(url,headers = headers)
        soup = BeautifulSoup(r.text,"html.parser")
        if (flag == 0):  ##Uscert
            sel = soup.select("article")
        elif (flag == 1):  ##Malwarebytes
            sel = soup.select("#articleBody")
        for s in sel:
            hashList = re.findall(r'[A-Fa-f0-9]{32,}',s.text.lower()) #md5,sha512(32bits,64bits)
            hashList = list(set(hashList)) ##去除重複
        hashList = GetXmlHash(i,df,hashList)
        df.loc[i,'Hash'] = str(hashList)
    return df

def GetCVE(df,flag):
## CVE
    print('[INFO]Parsing CVE start!')
    for i in range(len(df)):
        cveList = []
        url = df['Url'][i]
        r = requests.get(url,headers = headers)
        soup = BeautifulSoup(r.text,"html.parser")
        if (flag == 0):  ##Uscert
            sel = soup.select("article")
        elif (flag == 1):  ##Malwarebytes
            sel = soup.select("#articleBody")
        for s in sel:
            cveList = re.findall(r'cve-\d{4}-\d{4,7}|CVE-\d{4}-\d{4,7}',s.text)
            cveList = list(set(cveList)) ##去除重複
        df.loc[i,'CVE'] = str(cveList)
    return df

